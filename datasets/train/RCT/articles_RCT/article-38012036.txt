A Cluster Randomized Trial of Primary Care Practice Redesign to Integrate Behavioral Health for Those Who Need It Most: Patients With Multiple Chronic Conditions
INTRODUCTION
Comprehensive primary care for patients with chronic diseases that might include behavioral factors require targeted behavioral health services.1 Providing care for mental health, substance use disorders, and health behavior changes, and attending to psychosocial factors could decrease the negative health effects of tobacco, diet, physical inactivity, alcohol, and other substances, which together account for 38% of all US deaths,2,3 and prevent additional morbidity from treatment nonadherence, insomnia, anxiety, depression, and stress.4-6 Coordinating behavioral health and primary care services has shown improved outcomes for patients with depression (eg, Collaborative Care Model7) and patients with mixed depression and anxiety.8,9 Integrating primary and behavioral health care management across multiple chronic conditions (MCCs) has shown greater effectiveness than integration focused on a single diagnosis and could benefit patients, families, and the health care system.10-16

Integrated primary care and behavioral health (IBH) is “the care that results from a practice team of primary care and behavioral health clinicians, working together with patients and families, using a systematic and cost-effective approach to provide patient-centered care for a defined population.”17 Integration efforts can include population management, protocol-driven evidence-supported care, guideline-based external referrals, systematic needs identification, team-based care, and practice-wide approaches to patient engagement.17 Less intensive integration can include working with a Behavioral Health (BH) provider in the same building (ie, colocation) without shared scheduling and record systems.17 Integration of these services is known to be efficacious, but quantifying integration is complex, involving evaluation across domains of clinical services, workflow, workspace, integration of providers, patient identification procedures, and methods of engaging patients.18-21 More intensive integration efforts are hypothesized to result in better patient outcomes17 but have not been studied in broadly defined populations.

Practices that attempt to increase IBH often encounter barriers arising from health care system complexity.1 Structured implementation processes can address such barriers22 and some, such as implementation toolkits, have demonstrated innovation uptake in health care.23,24 Study authors (C.vE., R.K., B.L.) developed early versions of such an intervention to help practices enhance IBH by engaging frontline workers in redesigning processes while eliminating inefficient work. This approach was successful in establishing onsite BH in primary care, increasing care initiation, and decreasing time to first BH visit.25 The research team expanded on that approach, incorporating more implementation best practice strategies26,27 to create the current version of the integrated care toolkit tested in the present study.

The purpose of this initiative was to study the effect of a single approach to IBH improvement on outcomes for primary care patients experiencing MCCs and, secondarily, to study the effect on primary care efforts to enhance integration. We evaluated the real-world effectiveness of toolkit access and support in enhancing IBH and outcomes reported by patients with MCCs. We also explored associations between IBH and patient outcomes, toolkit completion and change in IBH, and toolkit completion and change in patient outcomes.


METHODS
Design
Our multidisciplinary research team included members in the fields of psychology, family medicine, internal medicine, clinical and translational science, education, art, biostatistics, communication, public health, bioinformatics, and health care operations, with a variety of backgrounds including clinicians, patients, family members, leaders, and researchers from across the United States. We performed a large-scale, pragmatic, cluster randomized, clinical effectiveness trial. Pragmatic trials speed the translation of research into practice28 by testing interventions under usual, rather than ideal, conditions.29 Primary care practices were randomized to the active or control group. We used an intention-to-treat analysis and conducted a difference-in-differences analysis of BH integration and patient-reported outcomes during the period 2018 to 2020, including the onset of the coronavirus disease 2019 (COVID-19) pandemic. Study methods30 and qualitative findings31 are reported elsewhere and are registered at ClinicalTrials.gov (NCT02868983). The University of Vermont Committee on Human Research in the Medical Sciences (#16-554) and institutional review boards at other participating locations approved the protocol.

Procedures
We recruited primary care practices during the period 2016 to 2018 that had a colocated behavioral health provider (BHP) (ie, psychologist, social worker, or licensed counselor) of =0.5 full-time equivalent, capable of billing insurers, using electronic health records, and with scores <75 on the Practice Integration Profile 1.0 (PIP), a measure of IBH.32 The sites included internal medicine, family medicine, small and large groups, for-profit, academic, and safety-net clinics recruited from practice networks across 13 US states using professional networks, association listservs, and conference presentations. Measures of practice integration were collected from 42 randomized practices.

We recruited patient participants from the 41 practices able to provide data on eligible patients. A third party reviewed electronic health records to identify adult patients from each practice with =1 chronic medical condition (arthritis; obstructive lung disease including emphysema, chronic bronchitis, or asthma; nongestational diabetes; or heart disease manifested as heart failure or hypertension), =1 chronic BH condition (diagnosis related to mood including anxiety or depression; chronic pain including headache, migraine, neuralgia, fibromyalgia, or chronic musculoskeletal pain; insomnia; irritable bowel syndrome; or substance misuse including substance use disorder, tobacco use, or problem drinking), or 3 medical conditions. Patients were randomly selected and contacted by e-mail, telephone, or postal mail with an invitation to join the study.

Intervention
Practices randomized to the active group were required to assemble a team with a facilitator. The intervention provided access to and support for workbooks to guide the planning, redesign, and implementation activities of a quality improvement (QI) project; online education tailored to clinic roles (physician, BHP, nurse, etc); an online learning community; and remote coaching for the team facilitator and QI team. Workbooks included specific tactics, such as care management, use of registries and population reports, and team-based care, known to be beneficial to delivering IBH to patients with MCCs. Given the pragmatic nature of the study, each QI team determined when to start and which elements of the intervention to use within an observation period from 2018 to 2020. An example of the toolkit can be found at https://sites.google.com/view/ibhpc/home.

Measures
Degree of practice integration was measured using the PIP, a survey of staff perceptions of integration32-34 (Supplemental Appendix). Practice Integration Profile total score (range 0-100) is the unweighted average of the following 6 survey domains: workflow, clinical services, workspace, integration of providers, patient identification, and patient engagement. A medical provider, BHP, administrator, and =1 additional practice member rated their practice’s performance using the PIP at baseline, midpoint, and 2 years. In addition, coaches monitored active practices’ progress and determined which practices completed workbook activities through implementation of =1 suggested practice change in =24 months.

Patients who agreed to participate completed the Patient-Reported Outcomes Measurement Information System35 (PROMIS-29) online survey at baseline, midpoint, and 2 years. The PROMIS-29 survey includes 8 domains (physical function, anxiety, depression, fatigue, sleep disturbance, social functioning, pain intensity, and pain interference) and 2 summary scores.36 Other measures included change in empathy,37 medication adherence,38 self-reported health care utilization,39 time lost due to disability,40 functional capacity,41 patient centeredness,42 depression,43 anxiety,44 asthma symptoms,45,46 substance use disorder,47 and problem drinking.48 All measures had published indications of adequate validity and reliability.32,33,35 For all measures, baseline data were collected before the COVID-19 pandemic; final measures were collected after the pandemic start.

Analysis
Intervention Effect on Patients’ PROMIS-29 Scores Primary outcomes were the changes (baseline to 2-year) in the 8 PROMIS-29 domain scores. The 2 PROMIS-29 summary scores were secondary outcomes. For each domain, we built a multivariate mixed linear regression model with change in outcome from baseline to 2 years as the dependent variable. Practice assignment to the intervention was the independent variable, modeled as a fixed effect, as were baseline level of the outcome measure and potential confounders (see below). A practice identifier was included as a random effect. We did not look for trends at midpoint because the intervention had not been in place long enough to affect outcomes.
We examined the possible confounding effects of 29 characteristics (Tables 1 and ?and2)2) on the relation between the intervention and each outcome. We compared the coefficient on the predictor from a mixed model with no fixed effect covariates to that from a model with a single covariate. For each analysis, we retained potential confounders associated with both outcome and predictor with P < .10 and also retained those affecting the association between the predictor and outcome.
The study was designed for 90% power to detect differences as small as 2.5 points between active and control arms in any of the 8 PROMIS-29 domain scales, consistent with minimally important differences specified for other PROMIS instruments of 2 to 8 points.49,50 We used the Bonferroni correction to maintain a = 0.05 as we examined the effect of the intervention on each of the 8 PROMIS-29 domains, resulting in a threshold of P = .00625.51 Additional models explored the association between the intervention and patient outcomes in subgroups based on patient characteristics, presence of qualifying conditions, number of qualifying conditions, neighborhood characteristics, and practice characteristics. These analyses were exploratory rather than hypothesis testing and were not adjusted for multiple comparisons.

Intervention Effect on Practices’ PIP Scores We tested whether the change in PIP total score differed between active and control practices. In a multivariate mixed linear regression model, change in PIP total score (baseline to 2-year) was the dependent variable, intervention assignment was the predictor, and covariates were selected from potential confounders identified using the procedure described above. Change in PIP domain scores was also explored. No random effects were modeled, and no correction for multiple comparisons was applied. With a sample size of 42 practices and an SD of 14.2 points, the study had 80% power to detect an effect of 12.7 points.
Exploratory Analyses To better understand our findings, we built several mixed linear models to explore associations not part of the original study design. We did not correct for multiple comparisons but tested for confounding as described above and included potential confounders in our models. To evaluate the association between practices’ baseline IBH on patient outcomes, we modeled each baseline and 2-year PROMIS-29 domain and summary score as dependent variables, baseline PIP total score as a fixed effect, and practice as a random effect. Noting that active practices varied in their fidelity using the intervention, we explored the association between intervention workbook completion and changes in IBH and patient outcomes. To evaluate the relation between intervention completion and change in IBH, we modeled change in PIP scores, which were adjusted for baseline PIP scores, as dependent variables, completion status as a fixed independent effect, and practice as a random effect. To determine if there was an association between intervention completion and change in patient outcomes, we modeled changes in patient outcomes, also adjusted for baseline outcomes, as dependent variables, completion status as a fixed independent effect, and practice as a random effect. All data were analyzed using Stata 17 (StataCorp LLC).
Go to:
RESULTS
Of 504,827 patient records reviewed electronically, 133,041 met the inclusion criteria, of which 66,804 were recruited and 4,407 responded from practices that stayed in the study. A total of 2,945 eligible patients did not drop out before randomization and completed the baseline PROMIS-29 survey; 2,426 (82%) completed follow-up 2 years later (Figure 1). The final sample (Table 1) had a greater prevalence of chronic disease and older average age (62 years vs 47 years) than the general population of US primary care patients, as described by the National Ambulatory Medical Care Survey,52 but was generally similar in race, ethnicity, gender, and rurality characteristics. Of 121 practices invited to participate, 52 declined, 24 were ineligible, 2 served as nonrandomized pilot sites (vanguard sites), and 1 dropped out before data collection, leaving 42 practices in the study. There were no significant differences in practice characteristics between active and control arms (Table 2).
Intervention Effect on Patients’ PROMIS-29 Scores
There was no difference in the amount of change in any of the 8 PROMIS-29 domains reported by patients receiving care from active practices compared with patients from control practices (Table 3 and Figure 2). Although mental health summary scores (adjusted for baseline and population density) improved in both groups (from 50.17 to 50.64 [? = 0.47; 95% CI, 0.10-0.84; P = .012] in the active group and 50.36 to 50.77 [? = 0.41; 95% CI, 0.11-0.70; P = .006] in the control group), the difference in improvement between the 2 groups was not statistically significant (? = -0.06; 95% CI, -0.51 to 0.39; P = .79) or clinically meaningful. Exploratory models based on patient subgroups revealed no consistent patterns among subgroups or outcomes.
Intervention Effect on Practices’ PIP Scores
Practice Integration Profile total score improved significantly during the study period for both active and control practices, but there was no statistically significant difference in improvement seen between the 2 groups (Table 3). Active practices (n = 20) improved their average PIP total scores from 59.4 to 71.6 (? = 12.2; 95% CI, 7.0-17.4; P <.001); control practices (n = 22) improved from 59.4 to 67.7 (? = 8.3; 95% CI, 1.5-15.2; P = .027). The difference in improvement between active and control groups was not significant (? = 3.9; 95% CI, -3.6 to 11.2; P = .3). However, PIP workflow domain scores improved significantly more in active than control practices (9.3 points; 95% CI, 1.7-16.9; P = .02), and all other PIP domains showed a pattern of nominally greater improvements (Table 3, Figure 2).

Baseline IBH
Regardless of assignment to active or control group, we observed a positive association between degree of integration (PIP total score) at baseline and patient mental health function (PROMIS-29 score) at baseline and 2 years (Table 4, Figure 3). Baseline anxiety, sleep disturbance, social participation, and mental health summary were significantly associated with greater PIP total score at baseline (eg, mental health summary: 0.05 points; 95% CI, 0-0.09; P = .05), with similar outcomes at 2 years (Table 4). Other PROMIS-29 scores showed a pattern of effect with nominally better patient function associated with greater PIP total score, although not significant when tested individually.
Intervention Workbook Completion
Active practices that completed intervention workbooks (n = 13) had significantly greater improvement in PIP total scores than practices that did not (n = 7) (9.9-point difference in change in PIP total score; 95% CI, 2.0-18.0; P = .02), with nominally greater changes in all PIP domain scores (Figure 4).
Patients who received care in practices that completed intervention workbooks reported significantly greater improvement in mental health summary (0.8; 95% CI, 0-1.6; P = .05) and social participation (1.4; 95% CI, 0.2-2.7; P = .02) (Figure 4) and nominally greater positive change on the remaining PROMIS-29 subscales than patients of active practices that did not complete workbooks, despite having access.


DISCUSSION
Practice access to the study intervention had no significant effect on the amount of change observed in patient-reported outcomes or PIP total score. Only the difference in PIP workflow improvement was large enough to attribute to active group assignment, which matches the structured focus of the toolkit on workflow redesign. However, study data allowed us to conduct additional analyses that could be important for future work attempting to understand how to evaluate and implement IBH.

Patients receiving care in practices that started the study with greater BH integration scores (before intervention) reported significantly better mental health function—both at baseline and at 2 years. Patients of practices that successfully completed intervention workbooks reported significantly greater improvements in mental health after 2 years. Although not proof of cause, these observations are consistent with the expectation that patients with MCCs benefit from efforts to enhance IBH. That total PIP score was associated with patient-reported outcomes and with implementation of IBH improvements supports the continued use of PIP as a measure of integration for future IBH enhancement activities.

Although the intervention was designed to support complex practice change and adapt to local context, only 13 of 20 active practices completed the intervention during the study period. Those 13 had significantly greater improvements in IBH and patient outcomes. Because confounding factors could affect both the ability to implement and the outcomes, these observations are not evidence of causation. As noted by Walunas and others, we need more studies to understand how much intervention is sufficient for practice change53-56 as well as how effective toolkits are in improving integration.

Limitations
The pragmatic design of the present study revealed real-world challenges to IBH. Participating practices in both groups experienced natural disasters, major work stoppages, loss of key personnel, and a pandemic. The research design allowed practices randomized to the control group to do QI work of their own (without access to the specific resources of the intervention) and allowed those in the active group to select the changes they perceived as most helpful. Too much flexibility of the intervention might have led to changes that were insufficiently strong to cause a clinic-wide effect on patient outcomes and integration. The resilience of practices in both groups, recruited based on their preexisting commitment to improve IBH, showed general improvement in integration but might have biased the outcomes and contributed to null results for the intervention. In particular, interpreting how the COVID-19 pandemic affected IBH is complex and requires further study.

A limitation of the present study is that patients who agreed to participate might be systematically different from those who declined. In addition, researchers did not have access to individual patient electronic health records after enrollment to know which patients were provided BH services and whether those who received additional services fared differently than others. Future studies distinguishing patients by service need and service use will provide additional insights. Continued research that includes the effect of BH services with meaningful clinical and service data, and relevant patient-reported outcomes for patients with MCCs, is needed to guide selection of the best IBH strategies and models (eg, Collaborative Care Model).7,57


CONCLUSIONS
Although the specific practice redesign intervention studied did significantly improve the workflow of integrated care, it had little effect on other practice or patient outcomes. Greater practice IBH levels at baseline were consistently associated with better patient mental and physical function. Practices that completed the intervention improved integration and patient outcomes more than those that did not. Future practice-based research will examine relations associated with practice engagement in the intervention steps and other factors to understand how to improve outcomes via integrated medical and behavioral health services for those who need it the most—patients with MCCs.


